{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd492d25-bccb-42fe-87e2-9ca7b0ac217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset opus100 (C:/Users/MMFraz/.cache/huggingface/datasets/opus100/en-ur/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114837c874a2453bb667fb904324f334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 753913\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Define the dataset name\n",
    "dataset_name = \"opus100\"\n",
    "\n",
    "# Load the Opus Parallel Corpus for English and Urdu\n",
    "opus_dataset = load_dataset(dataset_name, 'en-ur')\n",
    "\n",
    "# Display information about the dataset\n",
    "print(opus_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1159e31c-4ac1-42e9-aa53-65aa9fdb506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# tell pytorch to use cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e6914c-d162-4da3-be09-01bb791be52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input =[]\n",
    "target = []\n",
    "for i in opus_dataset[\"train\"][\"translation\"]:\n",
    "    if len(i[\"en\"])<=30:\n",
    "        input.append(i[\"en\"])\n",
    "        target.append(i[\"ur\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ff1210-0831-4184-a4d7-bc9ed12c6030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down!</td>\n",
       "      <td>نیچے!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I thought you said at dawn?</td>\n",
       "      <td>میں تم صبح میں نے کہا سوچا؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And thine raiment purify.</td>\n",
       "      <td>اور اپنے کپڑے پاک رکھو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- From the guilty.</td>\n",
       "      <td>مجرمین کے بارے میں</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>آگ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61647</th>\n",
       "      <td>IT WAS A FUN TRIP.</td>\n",
       "      <td>یہ ایک مذاق سفر تھا.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61648</th>\n",
       "      <td>Finch</td>\n",
       "      <td>فينچ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61649</th>\n",
       "      <td>And I'm sorry.</td>\n",
       "      <td>ءث¼غاط؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61650</th>\n",
       "      <td>You too, barbarian.</td>\n",
       "      <td>³تµµ, ¾ك¸¸ہخ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61651</th>\n",
       "      <td>Then when?</td>\n",
       "      <td>تو کب؟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61652 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           English                         Urdu\n",
       "0                            Down!                        نیچے!\n",
       "1      I thought you said at dawn?  میں تم صبح میں نے کہا سوچا؟\n",
       "2        And thine raiment purify.       اور اپنے کپڑے پاک رکھو\n",
       "3               - From the guilty.           مجرمین کے بارے میں\n",
       "4                            Fire!                          آگ!\n",
       "...                            ...                          ...\n",
       "61647           IT WAS A FUN TRIP.         یہ ایک مذاق سفر تھا.\n",
       "61648                        Finch                         فينچ\n",
       "61649               And I'm sorry.                      ءث¼غاط؟\n",
       "61650          You too, barbarian.                 ³تµµ, ¾ك¸¸ہخ\n",
       "61651                   Then when?                       تو کب؟\n",
       "\n",
       "[61652 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "eng_train = pd.DataFrame(input)\n",
    "ur_train= pd.DataFrame(target)\n",
    "data_train = pd.DataFrame()\n",
    "data_train[\"English\"]= eng_train\n",
    "data_train[\"Urdu\"]= ur_train\n",
    "\n",
    "display(data_train)\n",
    "# data_train = pd.concat([eng_train, ur_train],columns=[\"English\",\"Urdu\"], axis=1, join='inner')\n",
    "# display(data_train)\n",
    "\n",
    "# result_v.to_csv(\"F:\\\\NMT\\\\data_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d2e63a-3b0d-401f-ac39-04494b565173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_Eng(sen):\n",
    "    for char in sen:\n",
    "        if ord(char) in range(ord('a'), ord('z')+1) or ord(char) in range(ord('A'), ord('Z')+1):\n",
    "            return True\n",
    "    return False        \n",
    "\n",
    "target_updates=pd.DataFrame()\n",
    "for i in data_train.index:\n",
    "    if is_Eng(data_train[\"Urdu\"][i])== False:\n",
    "        new_row={\"English\":data_train[\"English\"][i], \"Urdu\":data_train[\"Urdu\"][i]}\n",
    "        target_updates= pd.concat([target_updates, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497b1637-c8bd-4411-a9b6-3ec5e5299856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down!</td>\n",
       "      <td>نیچے!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I thought you said at dawn?</td>\n",
       "      <td>میں تم صبح میں نے کہا سوچا؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And thine raiment purify.</td>\n",
       "      <td>اور اپنے کپڑے پاک رکھو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- From the guilty.</td>\n",
       "      <td>مجرمین کے بارے میں</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>آگ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56177</th>\n",
       "      <td>IT WAS A FUN TRIP.</td>\n",
       "      <td>یہ ایک مذاق سفر تھا.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56178</th>\n",
       "      <td>Finch</td>\n",
       "      <td>فينچ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56179</th>\n",
       "      <td>And I'm sorry.</td>\n",
       "      <td>ءث¼غاط؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56180</th>\n",
       "      <td>You too, barbarian.</td>\n",
       "      <td>³تµµ, ¾ك¸¸ہخ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56181</th>\n",
       "      <td>Then when?</td>\n",
       "      <td>تو کب؟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           English                         Urdu\n",
       "0                            Down!                        نیچے!\n",
       "1      I thought you said at dawn?  میں تم صبح میں نے کہا سوچا؟\n",
       "2        And thine raiment purify.       اور اپنے کپڑے پاک رکھو\n",
       "3               - From the guilty.           مجرمین کے بارے میں\n",
       "4                            Fire!                          آگ!\n",
       "...                            ...                          ...\n",
       "56177           IT WAS A FUN TRIP.         یہ ایک مذاق سفر تھا.\n",
       "56178                        Finch                         فينچ\n",
       "56179               And I'm sorry.                      ءث¼غاط؟\n",
       "56180          You too, barbarian.                 ³تµµ, ¾ك¸¸ہخ\n",
       "56181                   Then when?                       تو کب؟\n",
       "\n",
       "[56182 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(target_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46fa0a3-d1b3-47c1-b952-6b6945be0bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down!</td>\n",
       "      <td>نیچے!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And thine raiment purify.</td>\n",
       "      <td>اور اپنے کپڑے پاک رکھو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- From the guilty.</td>\n",
       "      <td>مجرمین کے بارے میں</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For me.</td>\n",
       "      <td>میرے لئے.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Motherfucker.</td>\n",
       "      <td>کمینی !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>while he fears [Allah],</td>\n",
       "      <td>اور وہ خوف خدا بھی رکھتاہے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>in whatever form He pleased?</td>\n",
       "      <td>اس نے جس صورت میں چاہاہے تیرے اجزائ کی ترکیب ک...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Compression level</td>\n",
       "      <td>دباؤ کا ریشو:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>on a tremendous day,</td>\n",
       "      <td>اس بڑے دن کے لیے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Ayn. Sin. Qaf.</td>\n",
       "      <td>عۤسۤقۤ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          English  \\\n",
       "0                           Down!   \n",
       "1       And thine raiment purify.   \n",
       "2              - From the guilty.   \n",
       "3                         For me.   \n",
       "4                   Motherfucker.   \n",
       "..                            ...   \n",
       "334       while he fears [Allah],   \n",
       "335  in whatever form He pleased?   \n",
       "336             Compression level   \n",
       "337          on a tremendous day,   \n",
       "338                Ayn. Sin. Qaf.   \n",
       "\n",
       "                                                  Urdu  \n",
       "0                                                نیچے!  \n",
       "1                               اور اپنے کپڑے پاک رکھو  \n",
       "2                                   مجرمین کے بارے میں  \n",
       "3                                            میرے لئے.  \n",
       "4                                              کمینی !  \n",
       "..                                                 ...  \n",
       "334                         اور وہ خوف خدا بھی رکھتاہے  \n",
       "335  اس نے جس صورت میں چاہاہے تیرے اجزائ کی ترکیب ک...  \n",
       "336                                      دباؤ کا ریشو:  \n",
       "337                                   اس بڑے دن کے لیے  \n",
       "338                                             عۤسۤقۤ  \n",
       "\n",
       "[339 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_v =[]\n",
    "target_v = []\n",
    "for i in opus_dataset[\"validation\"][\"translation\"]:\n",
    "    if len(i[\"en\"])<=30:\n",
    "        input_v.append(i[\"en\"])\n",
    "        target_v.append(i[\"ur\"])\n",
    "\n",
    "eng_val = pd.DataFrame(input_v)\n",
    "ur_val= pd.DataFrame(target_v)\n",
    "data_val = pd.DataFrame()\n",
    "data_val[\"English\"]= eng_val\n",
    "data_val[\"Urdu\"]= ur_val\n",
    "\n",
    "# display(data_val)\n",
    "\n",
    "target_val=pd.DataFrame()\n",
    "for i in data_val.index:\n",
    "    if is_Eng(data_val[\"Urdu\"][i])== False:\n",
    "        new_row={\"English\":data_train[\"English\"][i], \"Urdu\":data_train[\"Urdu\"][i]}\n",
    "        target_val= pd.concat([target_val, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "display(target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13fb5502-9f19-49f5-a6ae-e40dd5a2b2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought you said at dawn?</td>\n",
       "      <td>میں تم صبح میں نے کہا سوچا؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>آگ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For me.</td>\n",
       "      <td>میرے لئے.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mother, father,</td>\n",
       "      <td>اور اپنی ماں اور اپنے باپ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Motherfucker.</td>\n",
       "      <td>کمینی !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>-Tommy!</td>\n",
       "      <td>-Tommy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Aaron, my brother.</td>\n",
       "      <td>وہ کون میرا بھائی ہارون،</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>All right, what do you want?</td>\n",
       "      <td>ٹھیک ہے، تم کیا چاہتے ہو؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>And with fear (in his heart),</td>\n",
       "      <td>اور وہ (اپنے رب سے) ڈرتا بھی ہے،</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Mother and father,</td>\n",
       "      <td>اور ماں اور باپ،</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           English                              Urdu\n",
       "0      I thought you said at dawn?       میں تم صبح میں نے کہا سوچا؟\n",
       "1                            Fire!                               آگ!\n",
       "2                          For me.                         میرے لئے.\n",
       "3                  mother, father,         اور اپنی ماں اور اپنے باپ\n",
       "4                    Motherfucker.                           کمینی !\n",
       "..                             ...                               ...\n",
       "316                        -Tommy!                           -Tommy!\n",
       "317             Aaron, my brother.          وہ کون میرا بھائی ہارون،\n",
       "318   All right, what do you want?         ٹھیک ہے، تم کیا چاہتے ہو؟\n",
       "319  And with fear (in his heart),  اور وہ (اپنے رب سے) ڈرتا بھی ہے،\n",
       "320             Mother and father,                  اور ماں اور باپ،\n",
       "\n",
       "[321 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_test =[]\n",
    "target_test = []\n",
    "for i in opus_dataset[\"test\"][\"translation\"]:\n",
    "    if len(i[\"en\"])<=30:\n",
    "        input_test.append(i[\"en\"])\n",
    "        target_test.append(i[\"ur\"])\n",
    "\n",
    "eng_test = pd.DataFrame(input_test)\n",
    "ur_test= pd.DataFrame(target_test)\n",
    "data_test = pd.DataFrame()\n",
    "data_test[\"English\"]= eng_test\n",
    "data_test[\"Urdu\"]= ur_test\n",
    "\n",
    "# display(data_val)\n",
    "\n",
    "target_test=pd.DataFrame()\n",
    "for i in data_test.index:\n",
    "    if is_Eng(data_test[\"Urdu\"][i])== False:\n",
    "        new_row={\"English\":data_train[\"English\"][i], \"Urdu\":data_train[\"Urdu\"][i]}\n",
    "        target_test= pd.concat([target_test, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "display(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da6ef6df-906a-44aa-8e76-4278f5d5660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "# Initialize the mT5 tokenizer and model.\n",
    "tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-base\")\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "326c1718-bf71-4972-93b5-56c72bddf634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode your parallel data. eng to urdu\n",
    "inputs_train = tokenizer(target_updates[\"English\"].tolist(), max_length = 128, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "translations_train = tokenizer(target_updates[\"Urdu\"].tolist(), max_length= 128, return_tensors=\"pt\", padding=True, truncation=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f4ec610-b685-4877-9504-bb0de67c89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode your parallel data. eng to urdu\n",
    "inputs_val = tokenizer(target_val[\"English\"].tolist(), max_length = 128, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "translations_val = tokenizer(target_val[\"Urdu\"].tolist(), max_length= 128, return_tensors=\"pt\", padding=True, truncation=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efd102cb-9ec6-412f-b219-bc2724fdf091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch Dataset for training.\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, inputs, translations):\n",
    "        self.inputs = inputs\n",
    "        self.translations = translations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.inputs[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.inputs[\"attention_mask\"][idx],\n",
    "            \"translations\": self.translations[\"input_ids\"][idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1079dc0f-e741-4bb3-934e-b8c6855627b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TranslationDataset(inputs_train, translations_train)\n",
    "dataset_val = TranslationDataset(inputs_val, translations_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa26f13d-def9-47f8-9499-a9cc73d0b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MMFraz\\anaconda3\\envs\\NMT\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize a PyTorch DataLoader for training.\n",
    "\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define training hyperparameters.\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "# Initialize the optimizer.\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a14bbbf1-a425-4351-af4d-a26c39f4ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 7023/7023 [1:14:54<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.9608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Validation Loss: 1.7282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 7023/7023 [1:14:35<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.4377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 12.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Validation Loss: 1.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 7023/7023 [1:14:20<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.2712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Validation Loss: 0.6861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7023/7023 [1:14:31<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Validation Loss: 0.5658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 7023/7023 [1:15:10<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.1788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Validation Loss: 0.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 7023/7023 [1:14:34<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 0.1619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Validation Loss: 0.4749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 7023/7023 [1:14:21<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 0.1517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Validation Loss: 0.4573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 7023/7023 [1:14:22<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 0.1459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Validation Loss: 0.4496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7023/7023 [1:14:23<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 0.1423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Validation Loss: 0.4482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 7023/7023 [1:14:18<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 0.1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 43/43 [00:03<00:00, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Validation Loss: 0.4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fine-tuning loop.\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        translations = batch[\"translations\"]\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=translations)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if dataloader_val:\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch in tqdm(dataloader_val, desc=\"Validation\"):\n",
    "                val_input_ids = val_batch[\"input_ids\"]\n",
    "                val_attention_mask = val_batch[\"attention_mask\"]\n",
    "                val_translations = val_batch[\"translations\"]\n",
    "\n",
    "                val_outputs = model(input_ids=val_input_ids, attention_mask=val_attention_mask, labels=val_translations)\n",
    "                val_loss +=val_outputs.loss.item()\n",
    "\n",
    "            \n",
    "        avg_val_loss = val_loss / len(dataloader_val)\n",
    "        print(f\"Epoch {epoch + 1}, Average Validation Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aff92488-b229-42c7-8a87-dd662ec2634f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I thought you said at dawn?',\n",
       " 'Fire!',\n",
       " 'For me.',\n",
       " 'mother, father,',\n",
       " 'Motherfucker.',\n",
       " '- Shit.',\n",
       " 'Ask',\n",
       " 'And a pure cup.',\n",
       " 'He who purifies himself,',\n",
       " 'Simple',\n",
       " 'Without despatch!',\n",
       " 'And a tongue, and two lips?',\n",
       " 'It neither leaves, nor spares.',\n",
       " 'that will strip off the scalp.',\n",
       " 'the God of people,',\n",
       " 'That sounds like an excuse.',\n",
       " 'and drowned the rest.',\n",
       " 'Alif Lam Mim.',\n",
       " 'and We destroyed the rest.',\n",
       " 'Everybody was killed.',\n",
       " 'We sugar our tea.',\n",
       " 'Alif, Lam, Meem.',\n",
       " 'and gave you repose in sleep,',\n",
       " \"- That's the shitty one?\",\n",
       " 'PIN code required',\n",
       " 'Error editing connection',\n",
       " 'And an overflowing cup.',\n",
       " '%a %d %b',\n",
       " \"- He's on his way.\",\n",
       " 'I chose you for Myself.',\n",
       " 'By the midday brightness',\n",
       " 'the heavens are unveiled,',\n",
       " 'Open!',\n",
       " 'and persisted in the great sin',\n",
       " 'One moment, please.',\n",
       " \"- Who's your boy?\",\n",
       " 'How are the girls?',\n",
       " 'It is a blazing fire.',\n",
       " 'He frowned and turned away',\n",
       " 'And your clothing purify',\n",
       " 'He who denies and turns away.',\n",
       " 'By way of excuse or warning.',\n",
       " 'Then he followed a way',\n",
       " \"It's me, it's Desmond.\",\n",
       " 'No! I swear by the twilight',\n",
       " 'And gardens and watersprings.',\n",
       " 'Desmond.',\n",
       " 'This is not the plan!',\n",
       " \"they're all dead.\",\n",
       " 'Forget about your child.',\n",
       " 'Enable _Wireless',\n",
       " 'Captain, stop...',\n",
       " 'Then drowned the others.',\n",
       " 'Among Gardens and Springs;',\n",
       " '- I wish I could do more.',\n",
       " 'And the chargers at dawn,',\n",
       " 'What is this?',\n",
       " 'VLAN _id:',\n",
       " 'Color name',\n",
       " 'Add only if _newer',\n",
       " 'Come on, Ollie!',\n",
       " \"It's Doss.\",\n",
       " 'Should I make six?',\n",
       " 'Color name',\n",
       " 'So woe to those who pray',\n",
       " 'Stock label',\n",
       " 'He who produces the pasture.',\n",
       " 'Irish (Gaelic)',\n",
       " 'The King of men,',\n",
       " 'View the folders pane',\n",
       " 'Then Hell is the shelter.',\n",
       " 'Take a look at this.',\n",
       " 'then came down close',\n",
       " 'All right.',\n",
       " 'We have made them virgins,',\n",
       " 'About what they used to do.',\n",
       " 'shade and heat are not alike,',\n",
       " '[ SIGHS ]',\n",
       " '- Rangers...',\n",
       " 'As you are looking on.',\n",
       " 'These are the heirs',\n",
       " 'AH!',\n",
       " \"- Yes, ma'am\",\n",
       " 'By a Decree inscribed',\n",
       " 'Fleeing from a lion?',\n",
       " 'and this safe country (Mecca)!',\n",
       " 'Vires!',\n",
       " 'And his wife and his brother,',\n",
       " 'and be cheerful and joyous.',\n",
       " 'OKAY.',\n",
       " '- Why?',\n",
       " 'Okay.',\n",
       " 'And cups set at hand.',\n",
       " 'By the dawn',\n",
       " '- What if, what if!',\n",
       " 'What?',\n",
       " 'Get up!',\n",
       " 'Woe unto each sinful liar,',\n",
       " 'It is a Fire, intensely hot.',\n",
       " \"- No, no. You're certain?\",\n",
       " 'India',\n",
       " 'Aaron, my brother.',\n",
       " 'And by what you do not see.',\n",
       " 'fear God, then, and obey me.',\n",
       " 'When they sat by it (fire),',\n",
       " 'Why could you not obey?',\n",
       " 'Pick up the pace, ladies!',\n",
       " 'the heavens are unveiled,',\n",
       " 'I knew it!',\n",
       " 'The Night and its Homing;',\n",
       " 'And the even and the odd,',\n",
       " 'Indeed the tree of Zaqqum',\n",
       " 'Stock label',\n",
       " 'When the inevitable occurs.',\n",
       " 'For Granny.',\n",
       " 'Laughing and full of joy,',\n",
       " 'And Pharaoh of the Stakes.',\n",
       " 'Oh, my...',\n",
       " 'Sentimental',\n",
       " 'print operation status',\n",
       " 'You are one of the messengers.',\n",
       " 'and olive trees and date palms',\n",
       " 'In gardens of delight,',\n",
       " 'Of the jinn and of mankind.',\n",
       " 'labouring, weary,',\n",
       " 'when the sky is unveiled,',\n",
       " 'Even though they used to say.',\n",
       " 'and confirms the best promise,',\n",
       " 'offswitch',\n",
       " 'I got you.',\n",
       " '\"Yea, enter thou My Heaven!',\n",
       " 'and clustered spathes',\n",
       " 'Damn, dude!',\n",
       " 'No. New York. No red stamp.',\n",
       " 'October',\n",
       " 'Sleek writes:',\n",
       " '_Add Files...',\n",
       " 'the stars are dispersed,',\n",
       " 'Yeah, my situation.',\n",
       " 'Come on, Dog, you can do it.',\n",
       " '- No, wait.',\n",
       " \"Yeah, they're here.\",\n",
       " 'And believes in Al-Husna.',\n",
       " 'Hey!',\n",
       " 'Nor rebuff the seeker.',\n",
       " 'RECORDED DATA',\n",
       " 'Hungary',\n",
       " '- No, Sarge.',\n",
       " '- Give me a moment. - Yeah.',\n",
       " \"- And I'm always watching.\",\n",
       " \"1769 Cugnot's fardier\",\n",
       " 'By oath of this clear Book.',\n",
       " \"- Don't, Tom.\",\n",
       " 'What is the Catastrophe?',\n",
       " 'Are you all right?',\n",
       " 'Yes, sir.',\n",
       " 'Where are we now?',\n",
       " 'from a discharged living germ',\n",
       " 'Hello, Mr. Baker.',\n",
       " 'I called an artillery strike.',\n",
       " \"Well, he's tall\",\n",
       " 'Would it had been the end!',\n",
       " 'Gone from me is my authority.\"',\n",
       " 'For the living and the dead,',\n",
       " \"I can't forgive myself.\",\n",
       " 'And ye are classes three.',\n",
       " '- Uh-huh.',\n",
       " '@xronos2: I agree.',\n",
       " 'Then, are we not to die',\n",
       " 'Of what?',\n",
       " \"I'm done, sir.\",\n",
       " 'Just take it easy.',\n",
       " 'Is that when I was made aware?',\n",
       " \"We're being hunted.\",\n",
       " \"What's the number?\",\n",
       " 'Stock label',\n",
       " 'Right now ...',\n",
       " 'Then turned he away in pride',\n",
       " 'Stock label',\n",
       " 'Below are some:',\n",
       " '\"Begone! You are accursed:',\n",
       " '- You say \"cheats\". - He chit.',\n",
       " 'And laugh and not weep?',\n",
       " 'In a high Garden.',\n",
       " 'Vickers!',\n",
       " 'Stock label',\n",
       " 'shall cry for “perdition,”',\n",
       " 'the Lord of Moses and Aaron.’',\n",
       " \"He's looking for that arm.\",\n",
       " 'and dense orchards,',\n",
       " 'By the dawn',\n",
       " 'Secure the hallway.',\n",
       " 'and rich carpets levelled out.',\n",
       " 'I left it just the way it was.',\n",
       " '-Okay.',\n",
       " \"Don't trust him.\",\n",
       " 'And the Ten Nights,',\n",
       " 'and create you in pairs?',\n",
       " 'A multitude of those of old',\n",
       " '-Wait!',\n",
       " 'I can offer you a chance.',\n",
       " 'becoming scattered dust,',\n",
       " 'I wanted to prove you!',\n",
       " 'Dese_lect All',\n",
       " 'Hath He daughters and ye sons?',\n",
       " 'No.',\n",
       " 'concerning the sinners,',\n",
       " 'print operation status',\n",
       " 'These are the heirs',\n",
       " 'Where are you?',\n",
       " 'cushions ranged,',\n",
       " 'bearing a humbled look.',\n",
       " 'By the raging hurricanes,',\n",
       " 'Visible',\n",
       " \"It's okay.\",\n",
       " 'Tess know about this?',\n",
       " 'Thinking about making a weapon',\n",
       " 'The day the sky will tremble,',\n",
       " \"It's pretty.\",\n",
       " 'Make my task easy',\n",
       " 'and at almsgiving are active',\n",
       " 'Excuse me.',\n",
       " 'print operation status',\n",
       " 'That we may glorify Thee much',\n",
       " 'Click on a lowercase letter',\n",
       " 'Time for a bit of blasphemy!',\n",
       " 'I play football every day.',\n",
       " 'and Manat, the third one?',\n",
       " '- Ooh, hillbilly, huh?',\n",
       " 'It will engulf them.',\n",
       " 'USA_BAR_Georgia',\n",
       " 'No, my daughter!',\n",
       " 'You will be shown hell',\n",
       " 'Stupid fucking cunt!',\n",
       " 'And [by] Mount Sinai',\n",
       " 'Hey, Howard, ahh..',\n",
       " 'The threatened Hour is nigh.',\n",
       " 'Do you know how I made it?',\n",
       " 'Then he looked around,',\n",
       " 'Peace be Unto Ibrahim:',\n",
       " 'Bye.',\n",
       " 'No, there is no refuge.',\n",
       " '- Yes it is, sir.',\n",
       " 'By the sun and its radiance.',\n",
       " 'Say thou: O ye infidels!',\n",
       " 'When heaven is split open,',\n",
       " \"o'erspread with darkness --\",\n",
       " 'Benjamin Engel!',\n",
       " 'The Lord of Moses and Aaron.\"',\n",
       " 'for what they have done',\n",
       " 'Then a welcome of Inferno.',\n",
       " '-But I was your son.',\n",
       " 'Allah, the Eternal, Absolute;',\n",
       " 'Dominic Toretto, right?',\n",
       " 'As if they were tawny camels.',\n",
       " 'And banish all trepidation.',\n",
       " 'I cannot help you.',\n",
       " 'But when sight is confounded',\n",
       " 'On adorned couches, observing.',\n",
       " 'the Abyss shall be his home.',\n",
       " 'Nay, but ye will come to know!',\n",
       " 'Fresh from the garden.',\n",
       " 'You, uh...',\n",
       " '-Gentlemen.',\n",
       " 'for a suitable recompense.',\n",
       " 'Ta ke ca re!',\n",
       " 'Stock label',\n",
       " \"What aren't you telling me?\",\n",
       " 'So, woe to you! Woe to you!',\n",
       " 'Okay.',\n",
       " 'Unheady, uninebriating;',\n",
       " 'Ha-Mim.',\n",
       " \"It's time now to listen.\",\n",
       " 'Get the hell out here!',\n",
       " 'Domain %s defined from %s',\n",
       " 'For a certain appointed time,',\n",
       " 'He tapped him out.',\n",
       " 'Wireless network',\n",
       " 'Lo! hell will be his home.',\n",
       " 'and by this secure town:',\n",
       " 'Stock label',\n",
       " 'In the Gardens of delight,',\n",
       " 'Pharaoh and Thamood?',\n",
       " '- Why did you run off?',\n",
       " 'Computer stuff.',\n",
       " 'offswitch',\n",
       " 'Cancel',\n",
       " 'GhostScript',\n",
       " 'he will pray for annihilation',\n",
       " 'concerning the sinners,',\n",
       " 'Lots of places to hide.',\n",
       " 'You gotta get off the street!',\n",
       " 'What is the sure calamity!',\n",
       " 'Wel..',\n",
       " 'Just a trick of the woods',\n",
       " 'In the hands of scribes',\n",
       " 'Good, huh?',\n",
       " 'Yet you pay attention',\n",
       " 'He was trying to shoot me.',\n",
       " 'Honestly, we did!',\n",
       " 'and whose mixture is Tasnim,',\n",
       " '2000',\n",
       " 'The Lord of Musa and Haroun.',\n",
       " 'Definitely, yeah.',\n",
       " 'by the night swarming,',\n",
       " 'First:',\n",
       " 'Look, they cleared the city.',\n",
       " 'What is the Clatterer.',\n",
       " '“And also our forefathers?”',\n",
       " 'Select a Board',\n",
       " 'And our ancestors of old?”',\n",
       " 'Hold on to him.',\n",
       " \"It's ok.\",\n",
       " 'laughing, and rejoicing,',\n",
       " 'then caused it to wither away.',\n",
       " 'Who guard their sex',\n",
       " '-Tommy!',\n",
       " 'Aaron, my brother.',\n",
       " 'All right, what do you want?',\n",
       " 'And with fear (in his heart),',\n",
       " 'Mother and father,']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test[\"English\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7090112e-8cbb-440e-9e39-5ed364ffcefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'F:\\\\NMT\\\\MT5_opus.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e0777d-5b1e-41dd-85b3-6919b7f53410",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 16.00 GiB of which 0 bytes is free. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 874.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(target_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnglish\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Generate Urdu translations.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m translated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust max_length as needed.\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of translations to generate.\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# early_stopping=True\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Decode the generated token IDs to get the Urdu translations.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m urdu_translations \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mdecode(ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m ids \u001b[38;5;129;01min\u001b[39;00m translated_ids]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NMT\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NMT\\lib\\site-packages\\transformers\\generation\\utils.py:1602\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[0;32m   1586\u001b[0m         input_ids,\n\u001b[0;32m   1587\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1599\u001b[0m     )\n\u001b[0;32m   1600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[1;32m-> 1602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgreedy_search(\n\u001b[0;32m   1603\u001b[0m         input_ids,\n\u001b[0;32m   1604\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m   1605\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1606\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[0;32m   1607\u001b[0m         eos_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m   1608\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_scores,\n\u001b[0;32m   1609\u001b[0m         return_dict_in_generate\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1610\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1611\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1612\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1613\u001b[0m     )\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[0;32m   1616\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NMT\\lib\\site-packages\\transformers\\generation\\utils.py:2450\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2447\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2449\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2450\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   2451\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2452\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2453\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2454\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2455\u001b[0m )\n\u001b[0;32m   2457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2458\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NMT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NMT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NMT\\lib\\site-packages\\transformers\\models\\mt5\\modeling_mt5.py:1799\u001b[0m, in \u001b[0;36mMT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_word_embeddings:\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# Rescale output before projecting on vocab\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m sequence_output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m-> 1799\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NMT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NMT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NMT\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 16.00 GiB of which 0 bytes is free. Of the allocated memory 13.86 GiB is allocated by PyTorch, and 874.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Tokenize and encode the English sentences.\n",
    "inputs = tokenizer(target_test[\"English\"].tolist(), max_length=128, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# Generate Urdu translations.\n",
    "translated_ids = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    max_length=128,  # Adjust max_length as needed.\n",
    "    num_return_sequences=1,  # Number of translations to generate.\n",
    "    # early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode the generated token IDs to get the Urdu translations.\n",
    "urdu_translations = [tokenizer.decode(ids, skip_special_tokens=True) for ids in translated_ids]\n",
    "\n",
    "# Print the Urdu translations.\n",
    "for english, urdu in zip(target_test[\"English\"], urdu_translations):\n",
    "    print(f\"English: {english}\")\n",
    "    print(f\"Urdu: {urdu}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad68c4-7b2c-4c58-9890-57572f034349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "# refs = [['The dog bit the guy.', 'It was not unexpected.', 'The man bit him first.'],\n",
    "#         ['The dog had bit the man.', 'No one was surprised.', 'The man had bitten the dog.']]\n",
    "\n",
    "# hyps = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
    "\n",
    "\n",
    "refs = urdu_translations\n",
    "hyps = target_test[\"Urdu\"]\n",
    "\n",
    "bleu = BLEU()\n",
    "\n",
    "result = bleu.corpus_score(hyps, [refs])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
